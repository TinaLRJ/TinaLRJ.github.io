<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
	<style>
		body{
			color: #333;
		}
		#container{
			min-width: 1000px;
			width: 1000px;
/*			overflow: auto;
*/			margin: 50px auto;padding: 30px;
			/*zoom: 1;*/
*//*			border: 1px solid #ccc;background: #fc9;color: #fff;
*/		}
		#left{
			float: left;
			width: 230px;
			height: 250px;
			margin-left: 0px;
		}
		#right{
			float: left;
			width: auto;
			margin-left: 30px;
		}
		#name{
			font-size: 22.0pt;
		    mso-bidi-font-size: 24.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		        font-weight: bold;
		}
		#info{
		    font-size: 16.0pt;
		    mso-bidi-font-size: 16.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    margin-top: 30px;
		    margin-left: 5px;
		    margin-bottom: 10px;
		    
		}
		.clear{clear:both; height: 0; line-height: 0; font-size: 0}
		.Bio{
			font-size:16.0pt;
			mso-bidi-font-size:17.0pt;
			line-height:150%;
			font-family:Times;
			mso-bidi-font-family:Lato-Regular;
			text-align: justify;
		}
		span.SpellE {
		    mso-style-name: "";
		    mso-spl-e: yes;
		}
		span.Title{
			    font-size: 22.0pt;
			    mso-bidi-font-size: 17.0pt;
			    font-family: Times;
			    mso-bidi-font-family: Lato-Regular;
			    font: bold;
			    margin-top: 10px;
			    width: 1000px;
		}
		div.section{
			padding-top: 30px;
		}
		
		div.sub-left{
			float: left;
			width: 250px;
						
		}
		div.sub-left img{
			vertical-align: middle;
			horizontal-align: middle;
			margin-top: 10px;
		}
		
		div.sub-left span{
			height: 100%;
			display: inline-block;
			vertical-align: top;
						
		}
		div.sub-right{
			float: left;
			width: 750px;			
		}
		.paper{
			overflow: auto;
			zoom:1;
			border-top: 2px ;
			padding-bottom: 0px;
			min-height: 160px;

		}
		.paperTitle{
			font-size:14pt;
			mso-bidi-font-size:14pt;
			font-family:Calibri;
			mso-bidi-font-family:Calibri;
			margin-top: 10px;
			margin-bottom: 5px;
			font-weight: bold;
		}
		.paperName{
		    font-size: 12pt;
		    mso-bidi-font-size: 12pt;		    
		    font-family: Calibri;
		    mso-bidi-font-family: Times;
		    line-height:160%;
		    font-style: italic;
		}		
		.paperPub{
		    font-size: 14pt;
		    mso-bidi-font-size: 14pt;		    
		    font-family: Calibri;
		    mso-bidi-font-family: Times;		    
		    font-style: italic;
		    line-height:160%;
		}
		.paperLink{
		    font-size: 13.0pt;
		    mso-bidi-font-size: 13.0pt;		    
		    font-family: Calibri;
		    mso-bidi-font-family: Times;
		    line-height:170%;
		}
		.special{
		    margin-top: 0in;
		    margin-bottom: 0in;
		    margin-left: -.9pt;
		    margin-bottom: .0001pt;
		    text-indent: .9pt;
		    mso-pagination: none;
		    tab-stops: 13.75in;
		    mso-layout-grid-align: none;
		    text-autospace: none;
		}
		.long div.sub-left, .long div.sub-right{
			height: 300px;
			width: 980px;

		}
		.short div.sub-left, .short div.sub-right{
			height:150px;

		}
		div.sub-left,div.sub-right{
			height:200px;

		}
	</style>
</head>
<body>
	<div id="container">
		<div id="left">			
			<img width="200" height="230" src="imgs/photoLRJ.JPG">
		</div>
		<div id="right">
			<div id="name">Ruojing Li (李若敬) </div>
			<div id="info">

				Ph.D Candidate<p>
				National University of Defense Technology (NUDT)<p>
				Email: ruojingli@nudt.edu.cn<p>				
			</div>
			         <a href="https://www.researchgate.net/profile/Ruojing_Li4/research" target="_blank" rel="nofollow"><span>Research Gate</span></a>  |
			         <a href="https://github.com/TinaLRJ" target="_blank" rel="nofollow"><span>Github</span></a>  |
				 <a href="https://scholar.google.hk/citations?user=BPD9GbEAAAAJ&hl=zh-CN&oi=sra" target="_blank" rel="nofollow"><span>Google Scholar</span></a>  
			
			</div>

		<div class="clear"></div>
		<div class="section">
			<span class="Title"><b>Brief Bio</b></span><p>			
				<div class="Bio">
					I received the B.E. degree in electronic engineering from NUDT, Changsha, China, in 2020, where I'm currently pursuing the Ph.D. degree in information and communication engineering.
          My research interests include <b style="mso-bidi-font-weight:normal">infrared small target detection</b>, particularly on multiframe detection and deep learning.
				</div>


	<!-- <div class="section">
		<span class="Title"><b>News</b></span><p>
		<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		<div class="paper long"><b>
			<div class="sub-right">
			<div class="paperName"><b>	
			2024.03 | Our paper "Real-World Light Field Image Super-Resolution via Degradation Modulation" is accepted by <span style="color:red">IEEE TNNLS</span>.<br>
			2024.02 | Our paper "Learning Coupled Dictionaries from Unpaired Data for Image Super-Resolution" is accepted to <span style="color:red">CVPR 2024</span>.<br>
			2023.11 | One paper on multi-frame infrared small target detection is accepted to <span style="color:red">IEEE TNNLS</span>.<br>
			2023.09 | Four papers are selected as <span style="color:red">Highly Cited Papers</span> in the latest issue of ESI Index.<br>
			2023.07 | Two papers on light field image super-resolution and pointly supervised infrared small target detection are accepted to <span style="color:red">ICCV 2023</span>.<br>
			2023.02 | One paper on pointly supervised infrared small target detection is accepted to <span style="color:red">CVPR 2023</span>.<br>
			2023.01 | We are organizing <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/Stereo-Image-SR/tree/NTIRE2023" target="_blank" rel="nofollow">NTIRE Stereo Image SR Challenge</a> and <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/LF-Image-SR/tree/NTIRE2023" target="_blank" rel="nofollow">NTIRE LF Image SR Challenge</a> at CVPR 2023.<br>	
			2022.07 | Our paper "Dense Nested Attention Network for Infrared Small Target Detection" is accepted by <span style="color:red">IEEE TIP</span>. <br>
			2022.07 | Our paper "Exploring Fine-Grained Sparsity in Convolutional Neural Networks for Efficient Inference" is accepted by <span style="color:red">IEEE TPAMI</span>.<br>
			2022.03 | Two papers on network quantization and light field depth estimation are accepted to <span style="color:red">CVPR 2022</span>.<br>
			2022.02 | Our paper "Disentangling Light Fields for Super-Resolution and Disparity Estimation" is accepted by <span style="color:red">IEEE TPAMI</span>.<br>
			2022.01 | We are organizing <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/Stereo-Image-SR/tree/NTIRE2022" target="_blank" rel="nofollow">NTIRE Stereo Image Super-Resolution Challenge</a> at CVPR 2022.<br> 
			2021.10 | Our paper "Dense Dual-Attention Network for Light Field Image Super-Resolution" is accepted by IEEE TCSVT. [<a href="https://arxiv.org/pdf/2110.12114.pdf" target="_blank" rel="nofollow">pdf</a>]<br>				
			2021.10 | Our paper "Spatial-Angular Attention Network for Light Field Reconstruction" is accepted by <span style="color:red">IEEE TIP</span>. <br>	
			2021.07 | Our paper "Learning a Single Network for Scale-Arbitrary Super-Resolution" is accepted to <span style="color:red">ICCV 2021</span>.<br>
			2021.03 | Two papers on single image super-resolution are accepted to <span style="color:red">CVPR 2021</span>.<br>
			2020.11 | Our paper "Light Field Image Super-Resolution Using Deformable Convolution" is accepted by <span style="color:red">IEEE TIP</span>.<br>
			2020.09 | An online tutorial (120 min in Chinese) regarding our Parallax Attention Mechanism is available <a href="https://www.shenlanxueyuan.com/open/course/77" target="_blank" rel="nofollow">here</a>.<br>
			2020.09 | Our paper "Parallax Attention for Unsupervised Stereo Correspondence Learning" is accepted by <span style="color:red">IEEE TPAMI</span>.<br>
			2020.07 | Our paper "Spatial-Angular Interaction for Light Field Image Super-Resolution" is accepted to <span style="color:red">ECCV 2020</span>.<br>	
			2019.12 | Our paper "DeOccNet: Learning to See Through Foreground Occlusions in Light Fields" is accepted to WACV 2020.<br>
			2019.03 | A large-scale dataset for stereo image super-resolution is available online at <a href="https://yingqianwang.github.io/Flickr1024" target="_blank" rel="nofollow">Flickr1024</a>. <br>
			2019.02 | Our paper "Learning Parallax Attention for Stereo Image Super-Resolution" is accepted to <span style="color:red">CVPR 2019</span>.<br><br>
			</b></div>
			</b></div>
		</b></div>
	</div> -->

      
	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2023</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: 
		
    <div class="paper short">
      <div class="sub-left">
        <span></span>
        <img border="0" width="200" height="130" src="imgs/DTUM.png">
      </div>
      <div class="sub-right">
        <div class="paperTitle">
          Direction-Coded Temporal U-Shape Module for Multiframe Infrared Small Target Detection
        </div>
        <div class="paperName">
          <b>Ruojing Li</b>, Wei An, Chao Xiao, Boyang Li, Yingqian Wang, Miao Li, Yulan Guo
        </div>
        <div class="paperPub">
          <span style="color:rgb(255, 0, 0)"> <b>IEEE TNNLS</b></span>, 2023.<br> 
        </div>
        <div class="paperLink">
          | <a href="https://ieeexplore.ieee.org/abstract/document/10321723" target="_blank" rel="nofollow">Paper</a>
          | <a href="https://github.com/TinaLRJ/Multi-frame-infrared-small-target-detection-DTUM" target="_blank" rel="nofollow">Code</a>	
        </div>
      </div>
    </div>none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/LESPS.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Mapping degeneration meets label evolution: Learning infrared small target detection with single point supervision
					</div>
					<div class="paperName">
						Xinyi Ying, Li Liu, Yingqian Wang, <b>Ruojing Li</b>, Nuo Chen, Zaiping Lin, Weidong Sheng, Shilin Zhou
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>CVPR</b></span>, 2023.<br> 
					</div>
					<div class="paperLink">
						| <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Ying_Mapping_Degeneration_Meets_Label_Evolution_Learning_Infrared_Small_Target_Detection_CVPR_2023_paper.pdf" target="_blank" rel="nofollow">Paper</a>
						| <a href="https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ying_Mapping_Degeneration_Meets_CVPR_2023_supplemental.pdf" target="_blank" rel="nofollow">Supp</a>
						| <a href="https://xinyiying.github.io/LESPS/" target="_blank" rel="nofollow">Webpage</a>						
						| <a href="https://github.com/XinyiYing/LESPS" target="_blank" rel="nofollow">Code</a>	
					</div>
				</div>
			</div>
		

    
	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2021</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="imgs/DSFNet.JPG" width="200" height="130">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						DSFNet: Dynamic and static fusion network for moving object detection in satellite videos
					</div>
					<div class="paperName">
						Chao Xiao, Qian Yin, Xinyi Ying, <b>Ruojing Li</b>, Shuanglin Wu, Miao Li, Li Liu, Wei An, Zhijie Chen
					</div>
					<div class="paperPub">
						<span style="color:rgb(0, 0, 0)"> <b>IEEE GRSL</b></span>, 2021.<br> 
					</div>
					<div class="paperLink">
						| <a href="https://ieeexplore.ieee.org/abstract/document/9594855" target="_blank" rel="nofollow">Paper</a>												
					</div>
				</div>
			</div>

    
<div class="section">
				<span class="Title"><b>Academic Services</b></span><p>
				<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
				<div class="paperName"><b>
					Challenge Organization:<br>
					<a href="http://prcv.cn/?competition_128/" target="_blank" rel="nofollow">Wide Area Infrared Small Target Detection Challenge @ PRCV 2024</a>,<br>
					<a href="" target="_blank" rel="nofollow">Resourse-Limited Infrared Small Target Detection Challenge @ ICPR 2024</a>,<br>
					<br>
					Reviewer:<br>
					<br>					
					......<br>
					<br>
					</b></div>
			</div>		

			<div class="section">
				<span class="Title"><b>Teaching Assistance</b></span><p>
				<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
				<div class="paperName"><b>
					Lecture: Analog Electronic Technology (Spring Term, 2021)<br>
					Lecture: Analog Electronic Technology (Autumn Term, 2023)<br>
				</b></div>
			</div>
		
		
			
		

			<div class="section">
				<span class="Title"><b>Awards & Honors</b></span><p>
				<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
				<div class="paperName"><b>
					2020 | Outstanding Bachelor Dissertation Award of NUDT<br>
					2019 | Excellent Student of NUDT<br>
					2018 | Excellent Student of NUDT<br>
					2017 | Excellent Student of NUDT<br>
				</b></div>
			</div>		

			<!-- Last update time begjin -->
			<div style="border-top: 3px solid #555; text-align: center;">
				<p style="color: #555;">Last updated: 2024-04-14</p>
			</div>
			<!-- Last update time end -->

	</div>
	
</body>
</html>
